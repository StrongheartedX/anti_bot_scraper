#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ë¶€ë™ì‚° ìƒì„¸ ë§¤ë¬¼ ì •ë³´ í¬ë¡¤ëŸ¬ (ì¸ê°„í˜• ë§µ ì´ë™ + ë§¤ë¬¼ ìƒì„¸ í™•ì¥)

ì´ ìŠ¤í¬ë˜í¼ëŠ” ë„¤ì´ë²„ ë¶€ë™ì‚°ì—ì„œ ë§¤ë¬¼ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
Anti-bot ìš°íšŒ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ ,
ê°­íˆ¬ì ê¸°íšŒë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import asyncio, math, random, re
from datetime import datetime
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import pandas as pd
from playwright.async_api import async_playwright

# ======== ì„¤ì • ========
# ì´ ì„¤ì •ê°’ë“¤ì„ ìˆ˜ì •í•˜ì—¬ ìˆ˜ì§‘ ë²”ìœ„ì™€ ì„±ëŠ¥ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ìì„¸í•œ ì„¤ëª…ì€ README.mdì˜ "ì„¤ì • ìƒì„¸ ì„¤ëª…" ì„¹ì…˜ì„ ì°¸ê³ í•˜ì„¸ìš”.

KOR_BOUNDS = (33.0, 39.5, 124.0, 132.1)  # í•œêµ­ ì˜í†  ë²”ìœ„ (ì œì£¼ë„~ê°•ì›ë„, ì„œí•´~ë™í•´)
MAX_COMPLEX_DETAIL = 800                   # ë°©ë¬¸í•  ë‹¨ì§€/ê±´ë¬¼ ìµœëŒ€ ê°œìˆ˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼)
MAX_ARTICLE_DETAIL = 10000                 # ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ë§¤ë¬¼ ìµœëŒ€ ê°œìˆ˜
USE_MOBILE_DETAIL = True                   # ëª¨ë°”ì¼ í˜ì´ì§€ ì‚¬ìš© (ë” ë¹ ë¥´ê³  ì•ˆì •ì )
ONLY_WITH_PREV_JEONSE = True               # ê³¼ê±° ì „ì„¸ ê¸°ë¡ì´ ìˆëŠ” ë§¤ë¬¼ë§Œ ìˆ˜ì§‘ (ê°­íˆ¬ì ë¶„ì„ìš©)
BLOCK_HEAVY_RESOURCES = True               # ì´ë¯¸ì§€/í°íŠ¸ ì°¨ë‹¨ (ì†ë„ 2-3ë°° í–¥ìƒ)
MIN_LISTING_COUNT = 2                      # ì´ ê°œìˆ˜ ì´ìƒ ë§¤ë¬¼ì´ ìˆëŠ” ë‹¨ì§€ë§Œ ìš°ì„  ì²˜ë¦¬
PRIORITIZE_BY_COUNT = False                # Trueë©´ ë§¤ë¬¼ ë§ì€ ë‹¨ì§€ë¶€í„° ë°©ë¬¸ (ì‹œê°„ ì œí•œ ì‹œ ìœ ìš©)
DETAIL_WORKERS = 12                        # ë™ì‹œì— ì²˜ë¦¬í•  ë¸Œë¼ìš°ì € íƒ­ ìˆ˜ (4-20 ê¶Œì¥)
GRID_RINGS = 1                             # ì¤‘ì‹¬ì—ì„œ ë°”ê¹¥ìœ¼ë¡œ ëª‡ ê³ ë¦¬ê¹Œì§€ ìŠ¤ìº”í• ì§€ (ë„“ì€ ì§€ì—­ì€ 2-3)
GRID_STEP_PX = 480                         # ê° ìŠ¤ìº” ì§€ì  ê°„ ê°„ê²© (ì‘ì„ìˆ˜ë¡ ì´˜ì´˜)
SWEEP_DWELL = 0.6                          # ê° ì§€ì ì—ì„œ ë¨¸ë¬´ëŠ” ì‹œê°„(ì´ˆ) - ë„ˆë¬´ ì§§ìœ¼ë©´ ë°ì´í„° ëˆ„ë½
ZOOM_MIN, ZOOM_MAX = 15, 17                # ì¤Œ ë ˆë²¨ ë²”ìœ„ (15=êµ¬ ë‹¨ìœ„, 17=ë™ë„¤ ë‹¨ìœ„)
ASSET_TYPES = "APT:VL"                     # "APT"=ì•„íŒŒíŠ¸ë§Œ, "VL"=ë¹Œë¼ë§Œ, "APT:VL"=ë‘˜ ë‹¤

ONLY_PREV_GT_SALE = True                   # Trueë©´ ê¸°ì „ì„¸ê¸ˆâ‰¥ë§¤ë§¤ê°€ ë§¤ë¬¼ë§Œ ê²°ê³¼ì— í¬í•¨ (ê°­íˆ¬ì í›„ë³´ë§Œ)
# =====================

# ë‹¨ì§€ë³„ ë©”íƒ€ì •ë³´ ì €ì¥ì†Œ (ì´ë¦„, ë§¤ë¬¼ ìˆ˜)
complex_meta = {}

def _build_scenarios():
    """
    ì‚¬ìš©ìê°€ ì„ íƒí•œ ìì‚° ìœ í˜•(ì•„íŒŒíŠ¸/ë¹Œë¼)ì— ë”°ë¼
    ì–´ë–¤ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí• ì§€ ê²°ì •í•©ë‹ˆë‹¤.
    
    APT â†’ /complexes ì—”ë“œí¬ì¸íŠ¸
    VL â†’ /houses ì—”ë“œí¬ì¸íŠ¸
    """
    want = set([s.strip().upper() for s in ASSET_TYPES.split(":") if s.strip()])
    scenarios = []
    if "APT" in want:
        scenarios.append(("complexes", "APT"))
    if "VL" in want:
        scenarios.append(("houses", "VL"))
    return scenarios

def pixel_to_ll(x: float, y: float, z: float):
    """
    í”½ì…€ ì¢Œí‘œë¥¼ ìœ„ë„/ê²½ë„ë¡œ ì—­ë³€í™˜í•©ë‹ˆë‹¤.
    
    ì§€ë„ë¥¼ ë“œë˜ê·¸í•  ë•Œ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.
    ë©”ë¥´ì¹´í† ë¥´ íˆ¬ì˜ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    scale = 256 * (2 ** z)
    lon = x / scale * 360.0 - 180.0
    n = math.pi - 2.0 * math.pi * y / scale
    lat = math.degrees(math.atan(math.sinh(n)))
    return lat, lon

async def grid_sweep(page, center_lat, center_lon, zoom, rings=1, step_px=360, dwell=0.5):
    """
    ì¤‘ì‹¬ ì¢Œí‘œ ì£¼ë³€ì„ ê·¸ë¦¬ë“œ íŒ¨í„´ìœ¼ë¡œ ìŠ¤ìº”í•©ë‹ˆë‹¤.
    
    ì™œ í•„ìš”í•œê°€?
    - í•œ ë²ˆì— ë³´ì´ëŠ” ë§µ ì˜ì—­ì€ ì œí•œì 
    - ì£¼ë³€ ì§€ì—­ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ìŠ¤ìº”í•´ì•¼ ë§¤ë¬¼ ëˆ„ë½ ë°©ì§€
    - ìœ„/ì•„ë˜ í–‰ë§Œ ìŠ¤ìº”í•˜ì—¬ ë´‡ì²˜ëŸ¼ ë³´ì´ì§€ ì•Šê²Œ í•¨
    
    ì˜ˆì‹œ: rings=1, step_px=480ì´ë©´ ì¤‘ì‹¬ ì£¼ë³€ 8-12ê°œ ì§€ì  ë°©ë¬¸
    """
    # ì¤‘ì‹¬ì ì˜ í”½ì…€ ì¢Œí‘œ ê³„ì‚°
    cx, cy = ll_to_pixel(center_lat, center_lon, zoom)
    coords = []
    
    # ê° ë§(ê³ ë¦¬)ë§ˆë‹¤ ìœ„/ì•„ë˜ í–‰ì˜ ì§€ì ë“¤ ìƒì„±
    for r in range(1, rings + 1):
        for dx in range(-r, r + 1):
            for dy in (-r, r):  # ìœ„, ì•„ë˜ í–‰ë§Œ (ì¤‘ê°„ í–‰ì€ ê±´ë„ˆëœ€)
                x, y = cx + dx * step_px, cy + dy * step_px
                coords.append(pixel_to_ll(x, y, zoom))

    # ìƒì„±ëœ ëª¨ë“  ì§€ì ì„ ìˆœíšŒí•˜ë©° ë§µ ì´ë™
    total = len(coords)
    for i, (lat_, lon_) in enumerate(coords, 1):
        print(f"   â†ª ìŠ¤ìœ• {i}/{total} ì´ë™ ì¤‘...")
        await drag_to_latlon(page, lat_, lon_)
        await page.mouse.wheel(0, -40)  # ì•½ê°„ ìŠ¤í¬ë¡¤í•˜ì—¬ ìƒˆ ë§ˆì»¤ ë¡œë”© íŠ¸ë¦¬ê±°
        await asyncio.sleep(dwell)


def clamp_korea(lat: float, lon: float):
    """
    ì¢Œí‘œê°€ í•œêµ­ ì˜í†  ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì œí•œí•©ë‹ˆë‹¤.
    
    ì˜ëª»ëœ ì¢Œí‘œ ì…ë ¥ ì‹œ ìë™ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ í•œêµ­ ë‚´ ì¢Œí‘œë¡œ ë³´ì •í•©ë‹ˆë‹¤.
    """
    mnLat, mxLat, mnLon, mxLon = KOR_BOUNDS
    return max(mnLat, min(lat, mxLat)), max(mnLon, min(lon, mxLon))

def ll_to_pixel(lat: float, lon: float, z: float):
    """
    ìœ„ë„/ê²½ë„ë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    ë©”ë¥´ì¹´í† ë¥´ íˆ¬ì˜ë²• ì‚¬ìš©:
    - êµ¬ì²´(ì§€êµ¬)ë¥¼ í‰ë©´(í™”ë©´)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìˆ˜í•™ ê³µì‹
    - ì •í™•í•œ ë§µ ë“œë˜ê·¸ë¥¼ ìœ„í•´ í•„ìˆ˜
    
    ì´ í•¨ìˆ˜ ë•ë¶„ì— "ê°•ë‚¨ì—­"ì´ë¼ëŠ” ìœ„ë„/ê²½ë„ë¥¼ í™”ë©´ì˜ ì •í™•í•œ í”½ì…€ë¡œ ì´ë™ ê°€ëŠ¥
    """
    scale = 256 * (2 ** z)
    x = (lon + 180.0) / 360.0 * scale
    siny = math.sin(math.radians(lat))
    y = (0.5 - math.log((1 + siny) / (1 - siny)) / (4 * math.pi)) * scale
    return x, y

async def setup_blocking(ctx):
    """
    ë¬´ê±°ìš´ ë¦¬ì†ŒìŠ¤(ì´ë¯¸ì§€, í°íŠ¸, ë¯¸ë””ì–´)ë¥¼ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    
    íš¨ê³¼:
    - í˜ì´ì§€ ë¡œë”© ì†ë„ 2-3ë°° í–¥ìƒ
    - ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì ˆì•½
    - ë´‡ íƒì§€ì—ëŠ” ì˜í–¥ ì—†ìŒ (ì˜¤íˆë ¤ ìì—°ìŠ¤ëŸ¬ì›€)
    """
    if not BLOCK_HEAVY_RESOURCES:
        return
    async def _route(route):
        rt = route.request.resource_type
        if rt in ("image", "media", "font"):
            return await route.abort()  # ì´ë¯¸ì§€/ë¯¸ë””ì–´/í°íŠ¸ ìš”ì²­ ì°¨ë‹¨
        return await route.continue_()
    await ctx.route("**/*", _route)


async def get_ms(page):
    """
    í˜„ì¬ í˜ì´ì§€ URLì—ì„œ ë§µ ìƒíƒœ(ìœ„ë„, ê²½ë„, ì¤Œ ë ˆë²¨)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ë„¤ì´ë²„ ì§€ë„ URL í˜•ì‹: ?ms=37.5608,126.9888,15
    â†’ ìœ„ë„ 37.5608, ê²½ë„ 126.9888, ì¤Œ ë ˆë²¨ 15
    
    ì´ ì •ë³´ë¡œ í˜„ì¬ ë§µ ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë™ì‘ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    u = urlparse(page.url)
    ms = parse_qs(u.query).get("ms", [None])[0]
    if not ms: 
        return None
    try:
        la, lo, zz = ms.split(",")
        return float(la), float(lo), float(zz)
    except Exception:
        return None

async def wheel_to_zoom(page, target_zoom: int, step_delay=0.3):
    """
    ë§ˆìš°ìŠ¤ íœ ë¡œ íŠ¹ì • ì¤Œ ë ˆë²¨ê¹Œì§€ í™•ëŒ€/ì¶•ì†Œí•©ë‹ˆë‹¤.
    
    ì‚¬ëŒì²˜ëŸ¼ í–‰ë™í•˜ê¸° ìœ„í•´:
    - í•œ ë²ˆì— í™• ë°”ê¾¸ì§€ ì•Šê³  ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤
    - ê° ìŠ¤í¬ë¡¤ ì‚¬ì´ì— ë”œë ˆì´
    - ëª©í‘œ ì¤Œì— ë„ë‹¬í•˜ë©´ ì •ì§€
    """
    for _ in range(20):
        cur = await get_ms(page)
        if not cur:
            await asyncio.sleep(0.3)
            continue
        _, _, z = cur
        z = round(z)
        if z == target_zoom:
            return  # ëª©í‘œ ë‹¬ì„±
        # í™•ëŒ€ í•„ìš”í•˜ë©´ -300 (ìœ„ë¡œ ìŠ¤í¬ë¡¤), ì¶•ì†Œ í•„ìš”í•˜ë©´ +300 (ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤)
        await page.mouse.move(960, 540)
        await page.mouse.wheel(0, -300 if target_zoom > z else 300)
        await asyncio.sleep(step_delay)

async def drag_to_latlon(page, lat: float, lon: float, tolerance_px=3.5):
    """
    ë§µì„ ë“œë˜ê·¸í•˜ì—¬ íŠ¹ì • ìœ„ë„/ê²½ë„ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    
    ì‚¬ëŒì²˜ëŸ¼ í–‰ë™í•˜ê¸° ìœ„í•´:
    - í•œ ë²ˆì— ì •í™•íˆ ì´ë™í•˜ì§€ ì•ŠìŒ
    - ì—¬ëŸ¬ ë²ˆ ë“œë˜ê·¸í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì ‘ê·¼
    - ë§ˆìš°ìŠ¤ ì´ë™ì„ 20ë‹¨ê³„ë¡œ ë¶€ë“œëŸ½ê²Œ (steps=20)
    - 3.5í”½ì…€ ì´ë‚´ ì˜¤ì°¨ë©´ ì¶©ë¶„íˆ ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ íŒë‹¨
    """
    for _ in range(18):
        cur = await get_ms(page)
        if not cur:
            await asyncio.sleep(0.3)
            continue
        cur_lat, cur_lon, z = cur
        
        # í˜„ì¬ ìœ„ì¹˜ì™€ ëª©í‘œ ìœ„ì¹˜ì˜ í”½ì…€ ê±°ë¦¬ ê³„ì‚°
        x1, y1 = ll_to_pixel(cur_lat, cur_lon, z)
        x2, y2 = ll_to_pixel(lat, lon, z)
        dx, dy = x2 - x1, y2 - y1
        dist = math.hypot(dx, dy)
        
        # ì¶©ë¶„íˆ ê°€ê¹Œìš°ë©´ ì¢…ë£Œ
        if dist <= tolerance_px:
            return
        
        # í•œ ë²ˆì— ìµœëŒ€ 800í”½ì…€ê¹Œì§€ë§Œ ì´ë™ (ìì—°ìŠ¤ëŸ½ê²Œ)
        step = min(800.0, dist)
        r = step / (dist + 1e-9)
        mx, my = dx * r, dy * r
        
        # ë“œë˜ê·¸ ë™ì‘ ìˆ˜í–‰
        await page.mouse.move(960, 540)
        await page.mouse.down()
        await page.mouse.move(960 - mx, 540 - my, steps=20)  # 20ë‹¨ê³„ë¡œ ë¶€ë“œëŸ½ê²Œ ì´ë™
        await page.mouse.up()
        await asyncio.sleep(0.35)

async def human_like_recenter(page, lat: float, lon: float, zoom: int):
    """
    ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë§µì˜ ì¤‘ì‹¬ì„ íŠ¹ì • ìœ„ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    
    ë´‡ íƒì§€ë¥¼ ìš°íšŒí•˜ëŠ” í•µì‹¬ ê¸°ë²•:
    1. ëœë¤í•˜ê²Œ ì¤Œ ì•„ì›ƒ (9-12ë ˆë²¨)
    2. ëª©í‘œ ìœ„ì¹˜ë¡œ ëŒ€ëµ ì´ë™
    3. ì›í•˜ëŠ” ì¤Œ ë ˆë²¨ë¡œ í™•ëŒ€
    4. ì •í™•í•œ ìœ„ì¹˜ë¡œ ë¯¸ì„¸ ì¡°ì •
    
    ì´ë ‡ê²Œ í•˜ë©´ "í•œ ë²ˆì— ì •í™•íˆ ì°¾ì•„ê°€ëŠ” ë´‡"ì²˜ëŸ¼ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    rand_out = random.randint(9, 12)  # ëœë¤ ì¤Œ ì•„ì›ƒ ë ˆë²¨
    await wheel_to_zoom(page, rand_out)
    await drag_to_latlon(page, lat, lon)
    await wheel_to_zoom(page, zoom)
    await drag_to_latlon(page, lat, lon)

async def switch_to_listing_markers(page):
    """
    ë„¤ì´ë²„ ë¶€ë™ì‚° ë§µì—ì„œ 'ë§¤ë¬¼ ë³´ê¸°' ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.
    
    ê¸°ë³¸ì€ 'ë‹¨ì§€' ë³´ê¸°ì¸ë°, 'ë§¤ë¬¼' ë³´ê¸°ë¡œ ë°”ê¿”ì•¼ ê°œë³„ ë§¤ë¬¼ ì •ë³´ê°€ ë‚˜ì˜µë‹ˆë‹¤.
    ì—¬ëŸ¬ ê°€ì§€ ë²„íŠ¼ í…ìŠ¤íŠ¸ë¥¼ ì‹œë„í•˜ì—¬ UI ë³€ê²½ì— ëŒ€ì‘í•©ë‹ˆë‹¤.
    """
    # 1ìˆœìœ„: ì§ì ‘ì ì¸ ë§¤ë¬¼ ê´€ë ¨ ë²„íŠ¼
    for txt in ["ìƒì„¸ë§¤ë¬¼ê²€ìƒ‰", "ë§¤ë¬¼", "ë§¤ë¬¼ê²€ìƒ‰", "ë§¤ë¬¼ ë³´ê¸°"]:
        try:
            await page.locator(f"text={txt}").first.click()
            await asyncio.sleep(0.5)
            return True
        except:
            pass
    
    # 2ìˆœìœ„: ë“œë¡­ë‹¤ìš´ ë°©ì‹
    try:
        await page.locator('button:has-text("ë‹¨ì§€")').first.click()
        await asyncio.sleep(0.3)
        await page.locator('text=ë§¤ë¬¼').first.click()
        await asyncio.sleep(0.5)
        return True
    except:
        return False


def parse_kr_money_to_won(s: str) -> int | None:
    """
    í•œêµ­ì‹ ê¸ˆì•¡ í‘œê¸°ë¥¼ ì›(â‚©) ë‹¨ìœ„ ìˆ«ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    ì²˜ë¦¬ ê°€ëŠ¥í•œ í˜•ì‹:
    - "3ì–µ 8,000ë§Œì›" â†’ 380,000,000
    - "8,500" â†’ 85,000,000 (ë§Œì› ë‹¨ìœ„ë¡œ ê°€ì •)
    - "7.5ì–µ" â†’ 750,000,000
    - "320000000ì›" â†’ 320,000,000
    
    ì´ í•¨ìˆ˜ ë•ë¶„ì— ë„¤ì´ë²„ì˜ ë‹¤ì–‘í•œ ê¸ˆì•¡ í‘œê¸°ë¥¼ í†µì¼ëœ ìˆ«ìë¡œ ì²˜ë¦¬ ê°€ëŠ¥
    """
    if not s:
        return None

    orig = s
    t = s.strip().replace(" ", "").replace(",", "")
    has_won = "ì›" in t
    t = t.replace("ì›", "")

    eok = 0  # ì–µ (100,000,000)
    man = 0  # ë§Œ (10,000)
    total = 0

    # "ì–µ" ë‹¨ìœ„ ì²˜ë¦¬ (ì†Œìˆ˜ì  í—ˆìš©: "7.5ì–µ")
    m = re.search(r"(\d+(?:\.\d+)?)ì–µ", t)
    if m:
        try:
            total += int(float(m.group(1)) * 100_000_000)
        except:
            pass
        
        # ì–µ ë’¤ì˜ ë§Œ ë‹¨ìœ„ ì²˜ë¦¬: "3ì–µ8000ë§Œ", "3ì–µ8000", "3ì–µ2ì²œ"
        m2 = re.search(r"ì–µ(\d+)ë§Œ", t)
        if m2:
            man = int(m2.group(1))
        else:
            m2 = re.search(r"ì–µ(\d+)$", t)
            if m2:
                man = int(m2.group(1))
            else:
                m2 = re.search(r"ì–µ(\d+)ì²œ", t)
                if m2:
                    man = int(m2.group(1)) * 1000

    else:
        # ì–µì´ ì—†ì„ ë•Œ ë§Œ/ì²œ ë‹¨ìœ„ ì²˜ë¦¬
        m = re.search(r"(\d+)ë§Œ", t)
        if m:
            man = int(m.group(1))
        else:
            m = re.search(r"(\d+)ì²œë§Œ?", t)
            if m:
                man = int(m.group(1)) * 1000

    # ìˆœìˆ˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
    # "ì›" í‘œê¸° ìˆìœ¼ë©´ ì› ë‹¨ìœ„, ì—†ìœ¼ë©´ ë§Œì› ë‹¨ìœ„ë¡œ ê°€ì •
    if total == 0 and man == 0 and re.fullmatch(r"\d+", t):
        return int(t) if has_won else int(t) * 10_000

    return total + man * 10_000


async def scrape_article_detail(detail_page, article_no: str) -> dict:
    """
    ë§¤ë¬¼ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¤‘ê°œì‚¬ ì •ë³´ì™€ ê³¼ê±° ì „ì„¸ê°€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ìˆ˜ì§‘ ì •ë³´:
    - ë¶€ë™ì‚° ìƒí˜¸ (ì˜ˆ: ê°•ë‚¨ë¶€ë™ì‚°)
    - ì¤‘ê°œì‚¬ ì´ë¦„ (ì˜ˆ: í™ê¸¸ë™)
    - ì—°ë½ì²˜ 2ê°œ
    - ê³¼ê±° ì „ì„¸ê°€ (ê¸°ì „ì„¸ê¸ˆ) â† ê°­íˆ¬ì ë¶„ì„ì˜ í•µì‹¬!
    - ìµœê·¼ Në…„ê°„ ì „ì„¸ê°€ ìµœê³ /ìµœì €
    
    ONLY_WITH_PREV_JEONSE=Trueë©´ ê¸°ì „ì„¸ê¸ˆ ì—†ëŠ” ë§¤ë¬¼ì€ ì¦‰ì‹œ ê±´ë„ˆëœ€ (ì‹œê°„ ì ˆì•½)
    """
    async def _goto(url: str):
        """í˜ì´ì§€ ì´ë™ + ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²˜ë¦¬"""
        await detail_page.goto(url, wait_until='domcontentloaded')
        await asyncio.sleep(0.3)
        # ë§Œì•½ fin.landë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë˜ë©´ ë‹¤ì‹œ ì›ë˜ URLë¡œ
        if "fin.land.naver.com" in detail_page.url:
            await detail_page.goto(f"https://m.land.naver.com/article/info/{article_no}",
                                   wait_until='domcontentloaded')
            await asyncio.sleep(0.3)

    # ë§¤ë¬¼ ì •ë³´ í˜ì´ì§€ ì ‘ê·¼ ì‹œë„
    await _goto(f"https://m.land.naver.com/article/info/{article_no}")
    try:
        body_txt = await detail_page.inner_text("body")
    except:
        body_txt = ""
    
    # í˜ì´ì§€ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì—ëŸ¬ í˜ì´ì§€ë©´ ë‹¤ë¥¸ URL ì‹œë„
    if ("ìš”ì²­í•˜ì‹  í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”" in body_txt) or (len(body_txt.strip()) < 50):
        await _goto(f"https://m.land.naver.com/article/view/{article_no}")
        try:
            body_txt = await detail_page.inner_text("body")
        except:
            body_txt = ""

    # -------- í”„ë¦¬ì²´í¬: ê¸°ì „ì„¸ê¸ˆ ë¨¼ì € í™•ì¸ --------
    # ê°­íˆ¬ì ë¶„ì„ì— ê¸°ì „ì„¸ê¸ˆì€ í•„ìˆ˜ì…ë‹ˆë‹¤.
    # ì—†ìœ¼ë©´ ë¶„ì„ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì‹œê°„ ë‚­ë¹„í•˜ì§€ ì•Šê³  ì¦‰ì‹œ ìŠ¤í‚µ
    def grab(regex, flags=0):
        """ì •ê·œì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ì¶”ì¶œ"""
        m = re.search(regex, body_txt, flags)
        return m.group(1).strip() if m else ""

    prev_jeonse_txt = grab(r"ê¸°ì „ì„¸ê¸ˆ\s*([\d,ì–µ\së§Œ]+)")
    prev_jeonse = parse_kr_money_to_won(prev_jeonse_txt) if prev_jeonse_txt else None
    
    if ONLY_WITH_PREV_JEONSE and not prev_jeonse:
        return {"__skip__": True}  # ê¸°ì „ì„¸ê¸ˆ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°

    # -------- ì „ì„¸ íƒ­ìœ¼ë¡œ ì „í™˜í•˜ì—¬ ê¸°ê°„ë³„ ìµœê³ /ìµœì € í™•ì¸ --------
    # ì‹¤ê±°ë˜ê°€ íƒ­ì—ì„œëŠ” ë§¤ë§¤ ì •ë³´ë§Œ ë‚˜ì˜¤ë¯€ë¡œ ì „ì„¸ íƒ­ìœ¼ë¡œ ì „í™˜ í•„ìš”
    try:
        await detail_page.locator("text=ì‹¤ê±°ë˜ê°€").first.click()
        await asyncio.sleep(0.2)
        await detail_page.locator("text=ì „ì„¸").first.click()
        await asyncio.sleep(0.25)
        body_txt = await detail_page.inner_text("body")
    except:
        pass

    # -------- ì¤‘ê°œì‚¬ ì •ë³´ ì¶”ì¶œ --------
    lines = [l.strip() for l in body_txt.splitlines() if l.strip()]
    agent_name, office, cand_idx = "", "", -1
    
    # 2-4ê¸€ì í•œê¸€ ì´ë¦„ ì°¾ê¸° (ì£¼ë³€ì— "ì¤‘ê°œì‚¬" í‚¤ì›Œë“œ ìˆëŠ”ì§€ í™•ì¸)
    for i, l in enumerate(lines):
        if re.fullmatch(r"[ê°€-í£]{2,4}", l) and l not in ("ì´ë¯¸ì§€","ìƒì„¸ë³´ê¸°","ì¤‘ê°œì‚¬","ì¤‘ê°œì†Œ"):
            ctx = "\n".join(lines[max(0,i-3):i+2])
            if ("ì¤‘ê°œì‚¬" in ctx) or ("í”„ë¡œí•„" in ctx) or ("ì¤‘ê°œì†Œ" in ctx):
                agent_name, cand_idx = l, i
                break
    
    # ì¤‘ê°œì‚¬ ì´ë¦„ ì•„ë˜ì—ì„œ "ê³µì¸ì¤‘ê°œì‚¬" ë˜ëŠ” "ë¶€ë™ì‚°" í¬í•¨ëœ ì¤„ ì°¾ê¸°
    office_pat = re.compile(r"(ê³µì¸ì¤‘ê°œì‚¬|ë¶€ë™ì‚°)")
    if cand_idx >= 0:
        for l in lines[cand_idx+1:cand_idx+6]:
            if office_pat.search(l) and ("ìƒì„¸ë³´ê¸°" not in l) and ("ì „í™”" not in l):
                office = l
                break
    
    # ë°±ì—…: "ì¤‘ê°œì†Œ" í‚¤ì›Œë“œë¡œ ìƒí˜¸ ì°¾ê¸°
    if not office:
        m = re.search(r"ì¤‘ê°œì†Œ\s+([^\n]+)", body_txt)
        if m:
            tmp = m.group(1).strip()
            if "ì´ë¯¸ì§€" not in tmp:
                office = tmp

    # -------- ì „ì„¸ ê¸°ê°„ë³„ ìµœê³ /ìµœì € ì¶”ì¶œ --------
    # "3ë…„ ë‚´ ìµœê³  3ì–µ 5ì²œ", "3ë…„ ë‚´ ìµœì € 3ì–µ 2ì²œ" ê°™ì€ íŒ¨í„´
    m_max = re.search(r"(\d+)\s*ë…„\s*ë‚´\s*ìµœê³ \s*([\d,ì–µ\së§Œ]+)", body_txt)
    m_min = re.search(r"(\d+)\s*ë…„\s*ë‚´\s*ìµœì €\s*([\d,ì–µ\së§Œ]+)", body_txt)
    
    period_years = int(m_max.group(1)) if m_max else (int(m_min.group(1)) if m_min else None)
    jeonse_max = parse_kr_money_to_won(m_max.group(2)) if m_max else None
    jeonse_min = parse_kr_money_to_won(m_min.group(2)) if m_min else None

    # -------- ì „í™”ë²ˆí˜¸ ì¶”ì¶œ --------
    # 02-1234-5678, 010-1234-5678 í˜•ì‹
    phones = re.findall(r"(0\d{1,2}-\d{3,4}-\d{4})", body_txt)
    phone1 = phones[0] if len(phones) >= 1 else ""
    phone2 = phones[1] if len(phones) >= 2 else ""

    return {
        "ë¶€ë™ì‚°ìƒí˜¸": office,
        "ì¤‘ê°œì‚¬ì´ë¦„": agent_name,
        "ì „í™”1": phone1,
        "ì „í™”2": phone2,
        "ì „ì„¸_ê¸°ê°„(ë…„)": period_years,
        "ì „ì„¸_ê¸°ê°„ë‚´_ìµœê³ (ì›)": jeonse_max,
        "ì „ì„¸_ê¸°ê°„ë‚´_ìµœì €(ì›)": jeonse_min,
        "ê¸°ì „ì„¸ê¸ˆ(ì›)": prev_jeonse,
    }

async def crawl_detailed(lat=37.5608, lon=126.9888, zoom=14):
    """
    ë©”ì¸ í¬ë¡¤ë§ ë¡œì§
    
    ì „ì²´ í”„ë¡œì„¸ìŠ¤:
    1. ë¸Œë¼ìš°ì € ì‹¤í–‰ (ë°ìŠ¤í¬í†± + ëª¨ë°”ì¼)
    2. ë„¤ì´ë²„ ë¶€ë™ì‚° ë§µ ì ‘ì†
    3. ì¤‘ì‹¬ ì¢Œí‘œ ì£¼ë³€ ê·¸ë¦¬ë“œ ìŠ¤ìœ• â†’ ë‹¨ì§€/ë§¤ë¬¼ ë§ˆì»¤ ìˆ˜ì§‘
    4. ë§¤ë¬¼ ë§ì€ ë‹¨ì§€ ìš°ì„  ë°©ë¬¸ â†’ ìƒì„¸ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    5. ê° ë§¤ë¬¼ì˜ ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ â†’ ì¤‘ê°œì‚¬ ì •ë³´ + ì „ì„¸ê°€ ìˆ˜ì§‘
    6. ê°­íˆ¬ì ë¶„ì„ â†’ ì—‘ì…€ ì €ì¥
    """
    # ì¢Œí‘œê°€ í•œêµ­ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ìë™ ë³´ì •
    lat, lon = clamp_korea(lat, lon)
    zoom = int(zoom)

    async with async_playwright() as p:
        print("\nğŸš€ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘...")
        print("\n5~10ì´ˆì˜ ë¡œë”©ì‹œê°„ì´ ìˆìœ¼ë‹ˆ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”")
        
        # -------- ë¸Œë¼ìš°ì € ì´ˆê¸°í™” --------
        # ë°ìŠ¤í¬í†± ë¸Œë¼ìš°ì €: ë§µ ë„¤ë¹„ê²Œì´ì…˜ìš©
        browser = await p.chromium.launch(headless=False)  # headless=Trueí•˜ë©´ í™”ë©´ ì•ˆ ë³´ì„
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        )
        await setup_blocking(context)  # ì´ë¯¸ì§€/í°íŠ¸ ì°¨ë‹¨ í™œì„±í™”
        page = await context.new_page()
        
        # webdriver ì†ì„± ìˆ¨ê¸°ê¸° (ë´‡ íƒì§€ ìš°íšŒ)
        await page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined});")

        # -------- ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” (ìƒì„¸ í˜ì´ì§€ìš©) --------
        # ëª¨ë°”ì¼ í˜ì´ì§€ê°€ ë” ê°€ë³ê³  ë¹ ë¦„
        if USE_MOBILE_DETAIL:
            print("ğŸ“± ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘... (ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ìš©)")
            device = p.devices["iPhone 14 Pro Max"]
            mctx = await browser.new_context(
                **device,
                locale="ko-KR",
                extra_http_headers={
                    "referer": "https://m.land.naver.com/",
                    "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                }
            )
        else:
            mctx = context

        await setup_blocking(mctx)

        # -------- ì›Œì»¤ íƒ­ í’€ ìƒì„± --------
        # ë™ì‹œì— ì—¬ëŸ¬ ë§¤ë¬¼ ìƒì„¸ í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¸Œë¼ìš°ì € íƒ­ë“¤
        # DETAIL_WORKERS=12ë©´ 12ê°œ íƒ­ì´ ë™ì‹œì— ì‘ë™
        worker_count = DETAIL_WORKERS if USE_MOBILE_DETAIL else 1
        detail_pages = []
        print(f"ğŸ”§ {worker_count}ê°œ ì›Œì»¤ íƒ­ ìƒì„± ì¤‘...")
        
        for _ in range(max(1, worker_count)):
            dp = await mctx.new_page()
            await dp.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.open = (u)=>{ location.href = u; };
            """)
            detail_pages.append(dp)

        # íƒ­ í: ì‚¬ìš© ê°€ëŠ¥í•œ íƒ­ì„ ê´€ë¦¬
        page_q = asyncio.Queue()
        for dp in detail_pages:
            page_q.put_nowait(dp)

        # -------- ë°ì´í„° ìˆ˜ì§‘ ë²„í¼ ì´ˆê¸°í™” --------
        complex_list, article_list, trade_history = [], [], []
        seen_complex, seen_article, seen_trade = set(), set(), set()
        flags = {"capture": False}  # ìˆ˜ì§‘ í™œì„±í™” í”Œë˜ê·¸

        async def handle_response(response):
            """
            ë„¤ì´ë²„ API ì‘ë‹µì„ ê°€ë¡œì±„ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
            
            ë„¤ì´ë²„ëŠ” ë§µì„ ì›€ì§ì¼ ë•Œë§ˆë‹¤ APIë¡œ ë§¤ë¬¼ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.
            ì´ í•¨ìˆ˜ê°€ ê·¸ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ë¡œì±„ì„œ íŒŒì‹±í•©ë‹ˆë‹¤.
            
            ìˆ˜ì§‘í•˜ëŠ” API ì¢…ë¥˜:
            1. single-markers: ë§µì— í‘œì‹œë˜ëŠ” ë‹¨ì§€/ê±´ë¬¼ ë§ˆì»¤
            2. /api/articles/complex|house/{id}: ë‹¨ì§€ë³„ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸
            3. /api/complexes/{id}/prices: ì‹¤ê±°ë˜ê°€ ì´ë ¥
            """
            if not flags["capture"]:
                return  # ì•„ì§ ìˆ˜ì§‘ ì‹œì‘ ì „
            
            url = response.url

            def _is_villa_marker(it: dict) -> bool:
                """ë§ˆì»¤ê°€ ë¹Œë¼/ì—°ë¦½ì¸ì§€ íŒë‹¨"""
                code = (it.get('realEstateTypeCode') or it.get('estateType') or it.get('rletTpCd') or '').upper()
                name = (it.get('realEstateTypeName') or it.get('estateTypeName') or it.get('rletTpNm') or '')
                if code:
                    return code == 'VL'
                return any(k in name for k in ('ë¹Œë¼','ì—°ë¦½','ë‹¤ì„¸ëŒ€'))

            def _is_villa_article(a: dict) -> bool:
                """ë§¤ë¬¼ì´ ë¹Œë¼/ì—°ë¦½ì¸ì§€ íŒë‹¨"""
                code = (a.get('realEstateTypeCode') or a.get('rletTpCd') or '').upper()
                name = (a.get('realEstateTypeName') or a.get('rletTpNm') or '')
                if code:
                    return code == 'VL'
                return any(k in name for k in ('ë¹Œë¼','ì—°ë¦½','ë‹¤ì„¸ëŒ€'))

            # 1) ë‹¨ì§€/ë¹Œë¼ ë§ˆì»¤ ìˆ˜ì§‘
            if ('complexes/single-markers' in url) or ('houses/single-markers' in url):
                try:
                    data = await response.json()
                    if isinstance(data, list):
                        for it in data:
                            # houses ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜¨ ê±´ë° VLì´ ì•„ë‹ˆë©´ ê±´ë„ˆëœ€
                            if 'houses/single-markers' in url and not _is_villa_marker(it):
                                continue
                            
                            cno = str(it.get('markerId') or it.get('complexNo') or it.get('houseNo') or '')
                            name = it.get('complexName') or it.get('houseName') or ''
                            cnt = (it.get('articleCount') or it.get('dealCount') or it.get('totalCount') or it.get('cnt') or 0)
                            
                            if cno:
                                if cno not in seen_complex:
                                    seen_complex.add(cno)
                                    complex_list.append(it)
                                
                                # ë©”íƒ€ì •ë³´ ì—…ë°ì´íŠ¸ (ì´ë¦„, ë§¤ë¬¼ ìˆ˜)
                                meta = complex_meta.setdefault(cno, {"name": name, "count": 0})
                                meta["name"] = name or meta["name"]
                                if isinstance(cnt, int) and cnt > meta["count"]:
                                    meta["count"] = cnt
                except:
                    pass

            # 2) ë‹¨ì§€ë³„ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
            elif ('/api/articles/complex/' in url) or ('/api/articles/house/' in url):
                try:
                    data = await response.json()
                    
                    # URLì—ì„œ ë‹¨ì§€ ID ì¶”ì¶œ
                    m = re.search(r'/api/articles/(?:complex|house)/(\d+)', url)
                    cno = m.group(1) if m else None
                    
                    # ì´ ë§¤ë¬¼ ìˆ˜ ì—…ë°ì´íŠ¸
                    total = data.get('totalCount') or data.get('count') or 0
                    if cno and total:
                        meta = complex_meta.setdefault(cno, {"name": "", "count": 0})
                        if total > meta["count"]:
                            meta["count"] = int(total)

                    # ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±
                    articles = data.get('articleList') or data.get('articles') or []
                    for a in articles:
                        # houses ì‘ë‹µì¸ë° VLì´ ì•„ë‹ˆë©´ ê±´ë„ˆëœ€
                        if '/api/articles/house/' in url and not _is_villa_article(a):
                            continue
                        
                        # ë§¤ë§¤ ê±°ë˜ë§Œ ìˆ˜ì§‘ (ì „ì„¸/ì›”ì„¸ ì œì™¸)
                        tcode = (a.get('tradeType') or "").upper()
                        tname = (a.get('tradeTypeName') or "").strip()
                        if tcode not in ('A1',) and tname not in ('ë§¤ë§¤', 'SALE'):
                            continue
                        
                        k = a.get('articleNo')
                        if k and k not in seen_article:
                            seen_article.add(k)
                            article_list.append(a)
                except:
                    pass

            # 3) ì‹¤ê±°ë˜ê°€ ì´ë ¥ ìˆ˜ì§‘
            elif ('/api/complexes/' in url) and ('/prices' in url):
                try:
                    data = await response.json()
                    if isinstance(data, list):
                        for t in data:
                            k = (t.get('dealDate'), t.get('area'), t.get('floor'), t.get('dealPrice'))
                            if k not in seen_trade:
                                seen_trade.add(k)
                                trade_history.append(t)
                except:
                    pass

            # 4) ë°±ì—…: ê¸°íƒ€ APIì—ì„œ ë§¤ë¬¼ ì°¾ê¸°
            elif '/api/' in url:
                try:
                    data = await response.json()
                except:
                    data = None

                def collect_from(obj):
                    """ì¬ê·€ì ìœ¼ë¡œ JSONì—ì„œ ë§¤ë¬¼ ì •ë³´ ì°¾ê¸°"""
                    added = 0
                    if isinstance(obj, dict):
                        if 'articleList' in obj and isinstance(obj['articleList'], list):
                            return collect_from(obj['articleList'])
                        for v in obj.values():
                            added += collect_from(v)
                    elif isinstance(obj, list):
                        for it in obj:
                            if isinstance(it, dict):
                                k = it.get('articleNo') or it.get('atclNo')
                                if k:
                                    tcode = (it.get('tradeType') or it.get('tradTp') or "").upper()
                                    tname = (it.get('tradeTypeName') or "").strip()
                                    if tcode not in ('A1',) and tname not in ('ë§¤ë§¤', 'SALE'):
                                        continue
                                    if k not in seen_article:
                                        seen_article.add(k)
                                        article_list.append(it)
                                        added += 1
                            else:
                                added += collect_from(it)
                    return added

                added = collect_from(data)
                if added:
                    print(f"âœ… ë§¤ë¬¼ ë°œê²¬: +{added}ê°œ  / ëˆ„ì  {len(seen_article)}ê°œ")

        # API ì‘ë‹µ ê°€ë¡œì±„ê¸° ì‹œì‘
        page.on('response', handle_response)

        # -------- 1ë‹¨ê³„: ë§µ ë„¤ë¹„ê²Œì´ì…˜ & ë°ì´í„° ìˆ˜ì§‘ --------
        print(f"\nğŸ“ ìˆ˜ì§‘ ìœ„ì¹˜: ìœ„ë„ {lat:.4f}, ê²½ë„ {lon:.4f}, ì¤Œ {zoom}")
        z_clamped = max(ZOOM_MIN, min(ZOOM_MAX, int(zoom)))

        scenarios = _build_scenarios()
        for base_kind, a_param in scenarios:
            base = f"https://new.land.naver.com/{base_kind}"
            url = urlunparse(urlparse(base)._replace(query=urlencode({
                'ms': f'{lat},{lon},{z_clamped}',
                'a': a_param,  # APT ë˜ëŠ” VL
                'b': 'A1',     # ë§¤ë§¤
            })))
            
            asset_type = "ì•„íŒŒíŠ¸" if a_param == "APT" else "ë¹Œë¼/ì—°ë¦½"
            print(f"\nğŸ˜ï¸  {asset_type} ë§¤ë¬¼ ìˆ˜ì§‘ ì‹œì‘...")
            await page.goto(url, wait_until='domcontentloaded')

            # ìº”ë²„ìŠ¤(ë§µ) ë¡œë”© ëŒ€ê¸°
            try:
                await page.wait_for_selector("canvas", timeout=20000)
            except:
                print("âš ï¸  ë§µ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ê³„ì† ì§„í–‰)")

            # ì²« API ì‘ë‹µ ëŒ€ê¸°
            try:
                await page.wait_for_response(
                    lambda r: (
                        (f"{base_kind}/single-markers" in r.url) or
                        ("/api/articles/complex/" in r.url) or
                        ("/api/articles/house/" in r.url) or
                        ("/api/map/" in r.url)
                    ),
                    timeout=20000
                )
            except:
                print("âš ï¸  API ì‘ë‹µ íƒ€ì„ì•„ì›ƒ (ê³„ì† ì§„í–‰)")

            print("ğŸ¯ ì‚¬ëŒì²˜ëŸ¼ ë§µ ì´ë™ ì¤‘... (ë´‡ íƒì§€ ìš°íšŒ)")
            await human_like_recenter(page, lat, lon, z_clamped)
            await switch_to_listing_markers(page)  # 'ë§¤ë¬¼ ë³´ê¸°' ëª¨ë“œë¡œ ì „í™˜
            await wheel_to_zoom(page, max(15, z_clamped))

            # ìˆ˜ì§‘ ì‹œì‘!
            flags["capture"] = True

            # ì²« ë§ˆì»¤ ë¡œë“œ íŠ¸ë¦¬ê±°
            await page.mouse.move(960, 540)
            await page.mouse.wheel(0, -60)
            await asyncio.sleep(0.8)

            # ì¤‘ì‹¬ ì£¼ë³€ ê·¸ë¦¬ë“œ ìŠ¤ìœ•
            print(f"ğŸ” ì£¼ë³€ ì§€ì—­ ìŠ¤ìº” ì¤‘... (ë§: {GRID_RINGS}, ê°„ê²©: {GRID_STEP_PX}px)")
            await grid_sweep(
                page,
                center_lat=lat, center_lon=lon,
                zoom=z_clamped, rings=GRID_RINGS,
                step_px=GRID_STEP_PX, dwell=SWEEP_DWELL,
            )

        print(f"\nâœ… 1ë‹¨ê³„ ì™„ë£Œ: ë‹¨ì§€ {len(seen_complex)}ê°œ, ë§¤ë¬¼ {len(seen_article)}ê°œ ë°œê²¬")

        # -------- 2ë‹¨ê³„: ë‹¨ì§€ë³„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ --------
        if complex_list:
            print(f"\nğŸ“‹ 2ë‹¨ê³„: ë‹¨ì§€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘... (ìµœëŒ€ {MAX_COMPLEX_DETAIL}ê°œ)")
            targets = []
            
            # ë‹¨ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ (ë§¤ë¬¼ìˆ˜, ID, ì´ë¦„, ì¢…ë¥˜) íŠœí”Œë¡œ ë³€í™˜
            for c in complex_list:
                cno = str(c.get('complexNo') or c.get('houseNo') or c.get('markerId') or '')
                kind = 'houses' if c.get('houseNo') else 'complexes'
                name = c.get('complexName') or c.get('houseName') or ''
                cnt = complex_meta.get(cno, {}).get("count", 0)
                targets.append((cnt, cno, name, kind))

            # ìµœì†Œ ë§¤ë¬¼ ìˆ˜ í•„í„°ë§
            targets = [t for t in targets if t[0] >= MIN_LISTING_COUNT]
            
            # ë§¤ë¬¼ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜µì…˜)
            if PRIORITIZE_BY_COUNT:
                targets.sort(key=lambda x: x[0], reverse=True)
                print(f"ğŸ’¡ ë§¤ë¬¼ì´ ë§ì€ ë‹¨ì§€ë¶€í„° ìš°ì„  ì²˜ë¦¬í•©ë‹ˆë‹¤")

            # íƒ€ê²Ÿì´ ë„ˆë¬´ ì ìœ¼ë©´ ë°±ì—… ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
            if not targets:
                print(f"âš ï¸  ë§¤ë¬¼â‰¥{MIN_LISTING_COUNT} ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒ...")
                for c in complex_list[:MAX_COMPLEX_DETAIL*2]:
                    cno = c.get('markerId') or c.get('complexNo') or ''
                    name = c.get('complexName') or ''
                    cnt = complex_meta.get(cno, {}).get("count", 0)
                    kind = 'houses' if c.get('houseNo') else 'complexes'
                    targets.append((cnt, cno, name, kind))
                targets.sort(key=lambda x: x[0], reverse=True)

            # ë‹¨ì§€ ë°©ë¬¸
            print(f"\nğŸ¯ {min(len(targets), MAX_COMPLEX_DETAIL)}ê°œ ë‹¨ì§€ ë°©ë¬¸ ì˜ˆì •")
            for idx, (cnt, complex_no, complex_name, kind) in enumerate(targets[:MAX_COMPLEX_DETAIL], 1):
                if not complex_no:
                    continue
                
                type_kr = "ë¹Œë¼/ì—°ë¦½" if kind == "houses" else "ì•„íŒŒíŠ¸"
                print(f"\n[{idx}/{min(MAX_COMPLEX_DETAIL, len(targets))}] {complex_name} ({type_kr}, ë§¤ë¬¼: {cnt}ê°œ)")

                detail_url = f"https://new.land.naver.com/{kind}/{complex_no}"
                await page.goto(detail_url, wait_until='domcontentloaded')
                await asyncio.sleep(1.0)

                # 'ë§¤ë§¤' íƒ­ í´ë¦­í•˜ì—¬ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ API í˜¸ì¶œ íŠ¸ë¦¬ê±°
                try:
                    await page.locator('button:has-text("ë§¤ë§¤")').first.click()
                    await asyncio.sleep(0.6)
                except:
                    pass

        # -------- 3ë‹¨ê³„: ë§¤ë¬¼ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ --------
        print(f"\nğŸ“Š ìˆ˜ì§‘ ìš”ì•½:")
        print(f"  - ë‹¨ì§€: {len(seen_complex)}ê°œ")
        print(f"  - ë§¤ë¬¼: {len(seen_article)}ê°œ")
        print(f"  - ì‹¤ê±°ë˜: {len(seen_trade)}ê±´")

        results = []

        # ê°€ê²© ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ê°­íˆ¬ì í›„ë³´ë¥¼ ë¨¼ì € ì°¾ê¸° ìœ„í•´)
        def _sale_price_of(a):
            raw = re.sub(r'^\s*ë§¤ë§¤\s*', '', (a.get('dealOrWarrantPrc', '') or '')).strip()
            return parse_kr_money_to_won(raw) or 10**12
        
        try:
            article_list.sort(key=_sale_price_of)
            print("\nğŸ’¡ ë§¤ë§¤ê°€ê°€ ë‚®ì€ ë§¤ë¬¼ë¶€í„° ì²˜ë¦¬í•©ë‹ˆë‹¤ (ê°­íˆ¬ì í›„ë³´ ìš°ì„ )")
        except Exception:
            pass

        limit = MAX_ARTICLE_DETAIL if MAX_ARTICLE_DETAIL else len(article_list)
        print(f"\nğŸ” 3ë‹¨ê³„: ë§¤ë¬¼ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘... (ìµœëŒ€ {limit}ê°œ)")
        print(f"   {worker_count}ê°œ ì›Œì»¤ê°€ ë™ì‹œì— ì‘ì—…í•©ë‹ˆë‹¤")

        async def fetch_one(a):
            """
            í•˜ë‚˜ì˜ ë§¤ë¬¼ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            
            í”„ë¡œì„¸ìŠ¤:
            1. ë§¤ë§¤ê°€ íŒŒì‹±
            2. ì›Œì»¤ íƒ­ í• ë‹¹ ë°›ê¸°
            3. ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ (ì¤‘ê°œì‚¬ ì •ë³´, ì „ì„¸ê°€)
            4. ê°­íˆ¬ì ë¶„ì„ (ë§¤ë§¤ê°€ vs ê¸°ì „ì„¸ê¸ˆ)
            5. í•„í„°ë§ (ê¸°ì „ì„¸ê¸ˆ >= ë§¤ë§¤ê°€ë§Œ í†µê³¼)
            """
            # ë§¤ë§¤ê°€ íŒŒì‹±
            raw_price = re.sub(r'^\s*ë§¤ë§¤\s*', '', (a.get("dealOrWarrantPrc", "") or "")).strip()
            deal_value_won = parse_kr_money_to_won(raw_price)

            # ì›Œì»¤ íƒ­ í• ë‹¹
            dp = await page_q.get()
            try:
                extra = await scrape_article_detail(dp, str(a.get("articleNo", "")))
            finally:
                await page_q.put(dp)  # íƒ­ ë°˜í™˜

            # ê¸°ì „ì„¸ê¸ˆ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            if extra.get("__skip__"):
                return None

            prev_j = extra.get("ê¸°ì „ì„¸ê¸ˆ(ì›)")

            # ê°­íˆ¬ì í•„í„°: ê¸°ì „ì„¸ê¸ˆ >= ë§¤ë§¤ê°€
            if ONLY_PREV_GT_SALE and (prev_j is None or deal_value_won is None or prev_j < deal_value_won):
                return None

            # ê°­ ê¸ˆì•¡/ë¹„ìœ¨ ê³„ì‚°
            gap_amount = (deal_value_won - prev_j) if (deal_value_won is not None and prev_j is not None) else None
            gap_ratio = (gap_amount / deal_value_won) if (gap_amount is not None and deal_value_won) else None

            return {
                "ë§¤ë¬¼ëª…": a.get("articleName", ""),
                "ë§¤ë¬¼ë²ˆí˜¸": str(a.get("articleNo", "")),
                "ê±°ë˜ìœ í˜•": a.get("tradeTypeName", ""),
                "ë§¤ë§¤ ê¸ˆì•¡(ì›)": deal_value_won,
                "ì¸µìˆ˜": a.get("floorInfo", ""),
                "ë©´ì (ã¡)": a.get("area1", ""),
                "ì „ìš©ë©´ì ": a.get("area2", ""),
                "ë°©í–¥": a.get("direction", ""),
                "íŠ¹ì§•": a.get("articleFeatureDesc", ""),
                "ë“±ë¡ì¼": a.get("articleConfirmYmd", ""),
                "ë¶€ë™ì‚°ìƒí˜¸": extra.get("ë¶€ë™ì‚°ìƒí˜¸", ""),
                "ì¤‘ê°œì‚¬ì´ë¦„": extra.get("ì¤‘ê°œì‚¬ì´ë¦„", ""),
                "ì „í™”1": extra.get("ì „í™”1", ""),
                "ì „í™”2": extra.get("ì „í™”2", ""),
                "ì „ì„¸_ê¸°ê°„(ë…„)": extra.get("ì „ì„¸_ê¸°ê°„(ë…„)"),
                "ì „ì„¸_ê¸°ê°„ë‚´_ìµœê³ (ì›)": extra.get("ì „ì„¸_ê¸°ê°„ë‚´_ìµœê³ (ì›)"),
                "ì „ì„¸_ê¸°ê°„ë‚´_ìµœì €(ì›)": extra.get("ì „ì„¸_ê¸°ê°„ë‚´_ìµœì €(ì›)"),
                "ê¸°ì „ì„¸ê¸ˆ(ì›)": prev_j,
                "ê°­ê¸ˆì•¡(ì›)": gap_amount,
                "ê°­ë¹„ìœ¨": gap_ratio,
            }

        # ëª¨ë“  ë§¤ë¬¼ì— ëŒ€í•´ ë¹„ë™ê¸° ì‘ì—… ìƒì„±
        tasks = [asyncio.create_task(fetch_one(a)) for a in article_list[:limit]]

        # ì‘ì—… ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
        processed = 0
        for coro in asyncio.as_completed(tasks):
            row = await coro
            if row:
                results.append(row)
                processed += 1
                if processed % 100 == 0:
                    print(f"   ì§„í–‰: {processed}/{limit} ì²˜ë¦¬ ì™„ë£Œ...")

        # -------- 4ë‹¨ê³„: ê²°ê³¼ ì €ì¥ --------
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        if results:
            print(f"\nğŸ’¾ ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘...")
            df = pd.DataFrame(results)
            out = f'ë§¤ë¬¼ì •ë³´_í™•ì¥_{ts}.xlsx'
            df.to_excel(out, index=False, engine='openpyxl')
            
            print(f"\n{'='*60}")
            print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"{'='*60}")
            print(f"ğŸ“ íŒŒì¼: {out}")
            print(f"ğŸ“Š ê°­íˆ¬ì í›„ë³´: {len(df)}ê°œ")
            
            if len(df) > 0:
                # ê°­ë¹„ìœ¨ ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°
                top5 = df.nsmallest(5, 'ê°­ë¹„ìœ¨')[['ë§¤ë¬¼ëª…', 'ë§¤ë§¤ ê¸ˆì•¡(ì›)', 'ê¸°ì „ì„¸ê¸ˆ(ì›)', 'ê°­ê¸ˆì•¡(ì›)', 'ê°­ë¹„ìœ¨']]
                print(f"\nğŸ¯ ê°­ë¹„ìœ¨ TOP 5:")
                for idx, row in top5.iterrows():
                    gap_pct = row['ê°­ë¹„ìœ¨'] * 100 if row['ê°­ë¹„ìœ¨'] else 0
                    sale_m = row['ë§¤ë§¤ ê¸ˆì•¡(ì›)'] / 100_000_000 if row['ë§¤ë§¤ ê¸ˆì•¡(ì›)'] else 0
                    gap_m = row['ê°­ê¸ˆì•¡(ì›)'] / 10_000_000 if row['ê°­ê¸ˆì•¡(ì›)'] else 0
                    print(f"   {idx+1}. {row['ë§¤ë¬¼ëª…'][:20]:20s} | ë§¤ë§¤ {sale_m:.1f}ì–µ | ê°­ {gap_m:.0f}ë°±ë§Œ ({gap_pct:.1f}%)")
        else:
            print(f"\nâš ï¸  ê°­íˆ¬ì ì¡°ê±´({ONLY_PREV_GT_SALE=})ì„ ë§Œì¡±í•˜ëŠ” ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ì„¤ì •ì„ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì§€ì—­ì„ ì‹œë„í•´ë³´ì„¸ìš”.")

        print("\nğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        await asyncio.sleep(0.5)
        await mctx.close()
        await browser.close()

def main():
    """
    í”„ë¡œê·¸ë¨ ì‹œì‘ì 
    
    ì‚¬ìš©ìë¡œë¶€í„° ì¢Œí‘œì™€ ì¤Œ ë ˆë²¨ì„ ì…ë ¥ë°›ì•„ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    """
    print("=" * 60)
    print("ğŸ˜ï¸  ë„¤ì´ë²„ ë¶€ë™ì‚° ê°­íˆ¬ì ìŠ¤í¬ë˜í¼")
    print("=" * 60)
    print("\nğŸ’¡ ì¢Œí‘œ ì°¾ëŠ” ë²•:")
    print("   1. https://map.naver.com ì ‘ì†")
    print("   2. ì›í•˜ëŠ” ì§€ì—­ ê²€ìƒ‰")
    print("   3. ë§ˆìš°ìŠ¤ ìš°í´ë¦­ â†’ 'URL ë³µì‚¬'")
    print("   4. URLì—ì„œ lat, lng ê°’ í™•ì¸")

    lat = float(input("\nğŸ“ ìœ„ë„ (ê¸°ë³¸: 37.5608): ").strip() or "37.5608")
    lon = float(input("ğŸ“ ê²½ë„ (ê¸°ë³¸: 126.9888): ").strip() or "126.9888")
    zoom = int(input("ğŸ” ì¤Œ (ê¸°ë³¸: 15, ë²”ìœ„: 15-17): ").strip() or "15")

    print(f"\n{'='*60}")
    print(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘")
    print(f"{'='*60}")
    print(f"ğŸ“Œ ìœ„ì¹˜: ìœ„ë„ {lat}, ê²½ë„ {lon}, ì¤Œ {zoom}")
    print(f"ğŸ¯ ì„¤ì •: {ASSET_TYPES}, ì›Œì»¤ {DETAIL_WORKERS}ê°œ")
    print(f"ğŸ’° í•„í„°: ê¸°ì „ì„¸ê¸ˆâ‰¥ë§¤ë§¤ê°€ = {ONLY_PREV_GT_SALE}")
    print(f"{'='*60}\n")

    asyncio.run(crawl_detailed(lat, lon, zoom))

if __name__ == "__main__":
    main()
